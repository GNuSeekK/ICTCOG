# ICTCOG 군특화 인공지능 교육과정

* 1일차 5.16 수업 업데이트
>  * **1 - 1. python programming.ipynb** 
>  * **1 - 2. Python 기초 문법 - Data Type**
 > 강의평 : 아예 처음 수업을 듣는 인원도 꽤 있어, 난이도 부분에서 조금 아쉬웠다. python의 기초만 배워서 다 알고 있던 내용들이었다. 하지만  마크다운을 쓰면서 내 코드를 정리하는 방식을 배웠다. 이때까지 colab으로 작성했었던 코드들은 목차 없이 단순히 코드들만 적혀 있는데, 이 수업에서 사용했던 markdown을 기반으로 정리를 하면 좋을 것 같다는 생각이 들었다.
---
* 2일차 5.22 수업 업데이트
  * **1 - 2. Python 기초 문법 - Data Type**
  * **1 - 3. Python 기초 문법 - if statement.ipynb**
  * **1 - 4. Python 기초 문법 - Iteration Statement.ipynb**
  > 강의평 : 메모리에 대한 설명, 포인터에 대한 설명들은 이미 공부했던 부분이긴 하지만, 전공자가 아닌 만큼 책으로 익혀 확실하지 않은 부분들이 있었고 그 부분들을 채워주는 강의가 있어서 도움이 되었다. 하지만 아직까지도 수업은 기초수준에 머물고 있고 python의 기초만 익히고 있기 때문에 쉽다고 느껴진다. 인공지능 관련된 기초 지식들을 배울기 위해 기초를 다진다는 생각으로 한번 더 공부한다는 마음가짐으로 임해야 겠다.

다음주 예고 - pandas, numpy, 시각화 (matplotlib, seaborn + plotly(최신 유행 시각화 도구))
plotly는 안하게 된다면 개인적으로라도 공부할 예정.
---
* 3일차 5.23 수업 업데이트
  * **1 - 5. Python 기초 문법 - Function**
  * **2 - 1. 파이썬의 모듈 사용하기**
  * **2 - 2 numpy 기초**
  > 강의평 : 오늘은 이전 수업보다는 빠르게 나가서 유익한 수업이였다. 특히나 프레임워크, 라이브러리, 모듈의 차이점에 대해 질문하고 그 대답을 받아 이때까지 궁금했던 것을 해결할 수 있었고, numpy에서 사용해보지 못했던 기능인 flatten과 ravel에 대해서 알게 되었다. 또한 lambda의 경우 잘 사용하지 않았지만 의외로 사용할 수 있는 부분이 있다는걸 알게 되어 다음에 코딩을 할 때 이용해 볼 수 있겠다고 생각했다.
---
* 4일차, 5일차 수업 업데이트 5.29~5.30
  * **1. 2 - 03 [Pandas] DataFrame, Series**
  * **2. 2 - 04 [Pandas] CSV 파일 읽어오기**
  * **3. 2 - 05 통계값 요약, 정렬**
  * **4. 2 - 06 [pandas] - 데이터 선택, 결측값 색인**
  * **5. 2 - 07 [pandas] - 데이터 프레임 복사, 인덱스, 변형**
  * **6. 2 - 08 [pandas] - 결측값 처리하기**
  * **7. 2 - 09 [pandas] - 데이터 프레임 변형**
  * **8. 2 - 10 [pandas] - 여러 데이터 프레임 다루기**
  * **9. 2 - 11 [pandas] Series, Datetime**
  * **10. 2 - 12 [pandas] apply, lambda**
  * **11. 2 - 13 [pandas] 데이터 프레임의 연산**
  * **12. 2 - 14 [pandas] 원-핫 인코딩**
  * **13. 2 - 15 [pandas] 부동산 데이터 전처리**
  * **14. 2 - 16 [pandas] 데이터 프레임 시각화**
  * **15. 2 - 17 [matplotlib] figure, plot 사용**
  * **16. 2 - 18 [matplotlib] scatterplot, 3d, imshow**
  > 강의평 : 휴가 도중 아버지의 환갑으로 인해 가족 여행 중 휴대폰으로 들어 제대로된 실습을 하지 못했다. 그래서 집으로 돌아와 코드를 복습하며 다시 하나씩 살펴보며 복습을 하였다. matplotlib의 경우 제대로 다뤄보지 않고 구글링을 통해 필요할 때만 접했기 때문에, 이 강의에서 기초부터 조금씩 알려주어 많은 도움이 되었다.
---
* 6~10일차 수업 업데이트 6.5, 6.12, 6.13, 6.19, 6.20
  * 격리 기간으로 인해 휴대폰으로만 수업을 들어 막사 복귀 후 사지방에서 업데이트 중
  * 6.21 ~
  * **1. 2 - 18 [matplotlib] scatterplot, 3d, imshow**
  * **2. 2 - 19 [seaborn] 시각화 종류**
    * 시각화를 통한 통계치를 보는 방법을 알게 됨.
  * **3. 2 - 20 [Data Analyze] CCTV, 인구수 데이터 분석**
    * pandas에서 이용했던 pivot table의 활용이나 info()의 중요성 등을 알게 됨.
  * **4. 2 - 21 [Data Analyze] 범죄 데이터 분석**
    * REST API 이용법을 조금 더 구체적으로 알게 되어 유익한 시간이였다. 이전 까지는 단순히 구글링을 통해 제대로 알지도 못하고 남의 코드 그대로 API를 이용했다면, 이제는 문서를 보면서 직접 API를 이용해 코딩하는 방법을 알게 되었다. 수업에서는 urllib 모듈을 이용해서 했지만, 이전에 다른 프로젝트를 진행할 때 사용 했었던 requests 모듈을 이용하면 어떨까 하여 따로 공부하면서 이용해 보니 확실히 urllib보다 편리성이 좋아 이후에도 urllib보다는 requests를 자주 이용할 것 같다.
  * **5. 2 - 22 [Data Analyze] 유튜브 데이터 분석**
    * 유튜브 데이터의 경우 한글 데이터로, 이전까지 했던 수치형 데이터가 아니라 문자형 데이터였다. soynlp를 통해 자연어 처리를 하는 방법을 복습하게 되었고 그 외에는 평소에 잘 사용해보지 않았던 pivot_table을 이용하는 방법을 실습하면서 한번씩 응용해보기도 하였다.
  * **6. 2 - 23 [Data Analyze] 코로나 데이터 분석**
    * folium 모듈을 이용해 지도를 처음 사용해보게 되어 의미있었던 시간. 특히 마지막에 CircleMarker를 이용해 전 세계 코로나 데이터를 한번에 볼 수 있다는 점에서 인상깊었음.
  * **6. 3 - 01 [머신러닝] 개요**
  > 강의평 : 시간이 지날수록 모르는 내용들이 등장하여 다행히 배우는 기분이 확실히 들고 있다. 시각화 툴인 matplotlib이나 seaborn을 배우는 것과 더불어, API를 이용하는 방법도 배우고 있어 이후 내 프로젝트를 진행함에 있어서 많은 도움이 될 것이라고 생각한다. 자연어 처리의 경우에는 나의 프로그램에는 사용하지 않지만, 이후 뉴스기사를 통한 주식투자 인공지능 프로그램을 만들때 상당히 도움이 될 것이라고 생각한다.
---
* 11~12일차 수업 업데이트 6.26, 6.27
  * **3 - 02 [머신러닝] A-Z**
    * GIGO(Garbage In Garbage Out) : 쓰레기가 들어가면 쓰레기가 나온다.
    * 데이터 스누핑 편향 : 가지고 있는 데이터셋을 모두 활용해 새로운 데이터 세트에 대한 예측이 불안정한 현상
    * scikit_learn - sklearn.model_selection.train_test_split : 훈련데이터와 테스트데이터를 나누는 함수
    * pandas - pandas.cut : 계층화 시키는 함수
    * scikit_learn - sklearn.model_selection.StratifiedShuffleSplit : 계층 분할 + Shuffle
    * scikit_learn - sklearn.preprocessing.OrdinalEncoder : 텍스트 범주를 숫자 범주로 바꾸는 함수
    * scikit_learn - sklearn.preprocessing.OneHotEncoder : 원핫인코딩 -> 하나만 강조
    * 스케일링 : 단위를 통일하거나, 일정한 규정에 맞게 변경하는 것
      * MinMax 스케일링(sklearn.preprocessing.MinMaxScaler) : 0~1사이의 값으로 맞추는 정규화(normalization)
      * Standard 스케일링(sklearn.preprocessing.StandardScaler) : 평균이 0이고 분산이 1이되는 표준화(Generalization)
    * scikit_learn - sklearn.pipeline.Pipeline : 파이프라인 함수 -> 전처리 및 이후 예측에 관한 것 까지 파이프라인 화 가능
      * 주의사항 : 마지막 단계 이전은 Transformer로 fit, transform, fit_transform 메소드가 존재해야 한다.
      * 마지막 단계에는 Tranformer(변환기)와 Estimator(추정기) 모두다 사용 가능하다.
    * scikit_learn : sklearn.linear_model.LinearRegression : 선형회귀모델
    * scikit_learn : sklearn.tree.DecisionTreeRegressor : 의사결정 트리
    * scikit_learn : sklearn.model_selection.cross_val_score : 교차검증(Cross Validation)
      * 테스트 세트를 이용하기 전, 훈련 세트 안에서 validation data를 나눠서 교차검증 하는 과정
    * scikit_learn : sklearn.ensemble.RandomForestRegressor : 랜덤포레스트 모델
    * scikit_learn : sklearn.model_selection.GridSearchCV : 모델에 대한 설정 매개변수인 최적의 하이퍼 파라미터를 찾는 과정(GridSearch + Cross Validation)
