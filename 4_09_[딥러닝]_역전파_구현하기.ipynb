{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 - 09 [딥러닝] 역전파 구현하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObu6k/wObIHDufExUYfxk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GNuSeekK/ICTCOG/blob/main/4_09_%5B%EB%94%A5%EB%9F%AC%EB%8B%9D%5D_%EC%97%AD%EC%A0%84%ED%8C%8C_%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEXDTfCyRjtF"
      },
      "source": [
        "# 계층 ( Layer )\n",
        "* 국소적 계산\n",
        "  * 내가 관심 있는 연산만 신경 쓰는 것\n",
        "  * **계층**별로 국소적 계산 일어 난다.\n",
        "    * 덧셈 계층에서는 덧셈만\n",
        "    * 곱셈 계층에서는 곱셈만\n",
        "    * ReLU 활성화 에서는 ReLU만\n",
        "  * 하나의 계층은 하나의 일만(**국소적**) 전문적으로 할 수 있어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZiCNV3JSlI5"
      },
      "source": [
        "# 1. 곱셈 계층 구현하기\n",
        "입력이 `x, y`일 때\n",
        "* `forward`(순전파) : `x * y`\n",
        "* `backward`(역전파) : `dx = 미분값 * y` `dy = 미분값 * x`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Evlj_0SoaL"
      },
      "source": [
        "class MulLayer:\n",
        "    # 생성자 ( 순전파 및 역전파, 필요에 따라 다른 여러 메소드에서 '같이' 사용할 변수를 생성 )\n",
        "    def __init__(self):\n",
        "        # 여기서는 변수만 만들어 놓기\n",
        "        self.x = None\n",
        "        self.y = None\n",
        "\n",
        "    # 순전파\n",
        "    def forward(self, x, y):\n",
        "        # 역전파 때 서로 반대방향으로 곱해주기 위해 x, y를 저장\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        # 순전파 연산\n",
        "        out = x * y\n",
        "        return out\n",
        "\n",
        "    # 역전파\n",
        "    def backward(self, dout):\n",
        "        # x 방향에 미분값(dout) * y\n",
        "        # y 방향에 미분값(dout) * x\n",
        "        dx = dout * self.y\n",
        "        dy = dout * self.x\n",
        "\n",
        "        # x가 먼저 들어오고 y가 나중에 들어왔으니 순서 맞춰주기\n",
        "        return dx, dy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJd4X2RUZjHE"
      },
      "source": [
        "곱셈 레이어 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v390S5sGZkM7",
        "outputId": "e9ce5a17-91c6-40bd-c3e0-85c6490a3e99"
      },
      "source": [
        "# 순전파\n",
        "apple = 100     # 사과 한개당 가격\n",
        "apple_cnt = 2   # 사과 개수\n",
        "tax = 1.1       # 소비세\n",
        "\n",
        "# 계층은 2개\n",
        "#   (apple * apple_cnt) * tax\n",
        "\n",
        "mul_apple_layer = MulLayer() # 사과 전체 가격을 구할 레이어\n",
        "mul_tax_layer   = MulLayer() # 소비세 까지 적용시킨 가격을 구할 레이어\n",
        "\n",
        "# 순전파 수행\n",
        "# 순서 중요\n",
        "# 계획한 순서 그대로 레이어를 배치해서 연산해야함\n",
        "# 결과물은 제대로 나오지만 역전파 할 때 문제가 된다\n",
        "\n",
        "# 순전파 때 A-B-C 순으로 했으면\n",
        "# 역전파 때는 C-B-A 순으로 하기\n",
        "\n",
        "# 사과 전체 가격\n",
        "apple_price = mul_apple_layer.forward(apple, apple_cnt)\n",
        "\n",
        "# 소비세 적용 가격\n",
        "price = mul_tax_layer.forward(apple_price, tax)\n",
        "\n",
        "print(f'최종 사과의 가격 : {round(price)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 사과의 가격 : 220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuM8FVozZ72c",
        "outputId": "a796ee55-abae-425a-9362-22cdee2d51dc"
      },
      "source": [
        "# 역전파 수행하기\n",
        "#   제일 마지막 값에 대한 미분값을 생각하기\n",
        "#   Δ돈통 / Δ포스기 = 1\n",
        "\n",
        "dprice = 1\n",
        "\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple, dapple_cnt = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(f'사과 전체 가격에 대한 미분값 - d돈통 / d사과전체가격 : {dapple_price}')\n",
        "print(f'사과 1개 가격에 대한 미분값 - d사과전체가격 / d사과1개가격 : {dapple}')\n",
        "print(f'사과 개수에 대한 미분값 - d돈통 / d사과개수 : {dapple_cnt}')\n",
        "print(f'소비세에 대한 미분값 - d돈통 / d소비세 : {dtax}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "사과 전체 가격에 대한 미분값 - d돈통 / d사과전체가격 : 1.1\n",
            "사과 1개 가격에 대한 미분값 - d사과전체가격 / d사과1개가격 : 2.2\n",
            "사과 개수에 대한 미분값 - d돈통 / d사과개수 : 110.00000000000001\n",
            "소비세에 대한 미분값 - d돈통 / d소비세 : 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkD7q9hIciKj"
      },
      "source": [
        "# 2. 덧셈 계층 구현하기\n",
        "* `forward` : `x + y`\n",
        "* `backward` : 뒷층에서 보낸 미분값에 `* 1`만 하면 된다. `dx = dout * 1, dy = dout*1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2sgTtkcdu3g"
      },
      "source": [
        "class AddLayer:\n",
        "    # 생성자 ( 순전파 및 역전파, 필요에 따라 다른 여러 메소드에서 '같이' 사용할 변수를 생성 )\n",
        "    def __init__(self):\n",
        "        # 할게 없다\n",
        "        pass\n",
        "\n",
        "    # 순전파\n",
        "    def forward(self, x, y):\n",
        "        # 순전파 연산\n",
        "        out = x + y\n",
        "        return out\n",
        "\n",
        "    # 역전파\n",
        "    def backward(self, dout):\n",
        "        # x 방향에 미분값(dout) * 1\n",
        "        # y 방향에 미분값(dout) * 1\n",
        "        dx = dout * 1\n",
        "        dy = dout * 1\n",
        "\n",
        "        # x가 먼저 들어오고 y가 나중에 들어왔으니 순서 맞춰주기\n",
        "        return dx, dy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qalj52TbfgDH"
      },
      "source": [
        "apple = 100 # 사과 가격\n",
        "apple_cnt = 2 # 사과 갯수\n",
        "\n",
        "orange = 150\n",
        "orange_cnt = 3\n",
        "\n",
        "tax = 1.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y4UAytif995"
      },
      "source": [
        "# 1 계층 - 사과와 오렌지 각각의 국소적 계산\n",
        "# ( 사과 1개 가격 * 사과 개수) (오렌지 1개 가격 * 오렌지 개수)\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_orange_layer = MulLayer()\n",
        "\n",
        "# 2 계층 - 사과 전체 가격 + 오렌지 전체 가격\n",
        "add_apple_orange_layer = AddLayer()\n",
        "\n",
        "# 3 계층 - 소비세 적용\n",
        "mul_tax_layer = MulLayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQjmZw_gPkB"
      },
      "source": [
        "# 순전파 계산\n",
        "# 1 계층 계산\n",
        "# 사과에 대한 국소적 계산\n",
        "apple_price = mul_apple_layer.forward(apple, apple_cnt)\n",
        "\n",
        "# 오렌지에 대한 국소적 계산\n",
        "orange_price = mul_orange_layer.forward(orange, orange_cnt)\n",
        "\n",
        "# 2계층 계산\n",
        "total_price = add_apple_orange_layer.forward(apple_price,orange_price)\n",
        "\n",
        "# 3계층 계산\n",
        "price = mul_tax_layer.forward(total_price, tax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3qUQVYemW4O",
        "outputId": "ce4f2107-e1f2-416b-d661-740574e22834"
      },
      "source": [
        "print(f'전체가격 : {price}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체가격 : 715.0000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-nDI--nJch"
      },
      "source": [
        "# 역전파\n",
        "dprice = 1 # d돈통 / d포스기\n",
        "\n",
        "# dprice / dtotal_price, dprice / dtax\n",
        "# d돈통 / d포스기 * d포스기 / d전체가격, d돈통 / d포스기 * d포스기 / d소비세\n",
        "dtotal_price, dtax = mul_tax_layer.backward(dprice)\n",
        "\n",
        "# d돈통 / dapple_price, d돈통 / dorange_price\n",
        "dapple_price, dorange_price = add_apple_orange_layer.backward(dtotal_price)\n",
        "\n",
        "# 사과와 오렌지에 대한 각각의 미분값 (국소적 미분)\n",
        "dapple, dapple_cnt = mul_apple_layer.backward(dapple_price)\n",
        "dorange, dorange_cnt = mul_orange_layer.backward(dorange_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4VyNfpzn8bq",
        "outputId": "416733e7-ddf3-4ab3-dbde-d1e2b808d5c1"
      },
      "source": [
        "print(\"사과 2개, 오렌지 3개의 가격 (소비세 적용) : {}\".format(price))\n",
        "print('전체 가격에 대한 미분 : {}'.format(dtotal_price))\n",
        "\n",
        "print(\"사과 전체 가격 미분 : {}\".format(dapple_price))\n",
        "print(\"사과 개수 미분 : {}\".format(dapple_cnt))\n",
        "print(\"사과 가격 미분 : {}\".format(dapple))\n",
        "\n",
        "print(\"오렌지 전체 가격 미분 : {}\".format(dorange_price))\n",
        "print(\"오렌지 개수 미분 : {}\".format(dorange_cnt))\n",
        "print(\"오렌지 가격 미분 : {}\".format(dorange))\n",
        "\n",
        "print(\"소비세 미분 : {}\".format(dtax))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "사과 2개, 오렌지 3개의 가격 (소비세 적용) : 715.0000000000001\n",
            "전체 가격에 대한 미분 : 1.1\n",
            "사과 전체 가격 미분 : 1.1\n",
            "사과 개수 미분 : 110.00000000000001\n",
            "사과 가격 미분 : 2.2\n",
            "오렌지 전체 가격 미분 : 1.1\n",
            "오렌지 개수 미분 : 165.0\n",
            "오렌지 가격 미분 : 3.3000000000000003\n",
            "소비세 미분 : 650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiA1U2Jvo8fd"
      },
      "source": [
        "# 신경망 레이어 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBGoWzWzqYd4"
      },
      "source": [
        "## ReLU 레이어\n",
        "\n",
        "relu의 순전파 수식\n",
        "$$\n",
        "y = \\begin{cases} \n",
        "x\\quad( x > 0 )\n",
        "\\\\ 0\\quad( x \\leq 0 )\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "relu의 역전파 수식\n",
        "\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial x} = \\begin{cases} \n",
        "1\\quad( x > 0 )\n",
        "\\\\ 0\\quad( x \\leq 0 )\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "* `forward` : 입력값이 0보다 작으면 0으로, 0보다 크면 입력값을 그대로 출력\n",
        "* `backward` : `forward`시에 0보다 작았으면 해당 위치의 값을 0으로 설정, 0보다 컸으면 변화율이 1이기 때문에 미분값을 그대로 유지\n",
        "* 비고 : 어떤 인덱스의 값이 음수였는지는 지를 저장. (인덱스 x), `mask`로 저장\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5RA7Glqzza"
      },
      "source": [
        "class ReLU:\n",
        "  def __init__(self):\n",
        "    # 순전파 때 어느 부분이 음수였고, 양수 였는지를 판단하는 mask를 만들고,\n",
        "    # 역전파 때 이 mask를 이용해서 음수였던 부분의 기울기(미분값)를 0으로 만든다.\n",
        "    self.mask = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    self.mask = (x <= 0) # 음수면 True, 양수면 False\n",
        "\n",
        "    out = x.copy() # 원본 배열 복사\n",
        "    out[self.mask] = 0 # 음수였던 부분을 0으로 만든다.\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    # 순전파 때 음수였던 부분을 0으로 만들었다.\n",
        "    #  음수였었던 부분을 기억하고 있다가.(self.mask) 미분값 전달 할 때 해당 인덱스를 0으로 만들어 주면 된다.\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbX0XhWtt3jD",
        "outputId": "e0cf8ce5-c596-406d-c8ae-ecfe3bf30831"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1.0, -0.5],\n",
        "              [-2.0, 3.0]])\n",
        "\n",
        "relu = ReLU()\n",
        "relu.forward(x) # 음수 였던 부분이 전부 0이 된다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNuI8yz4uFoT",
        "outputId": "5ad98e31-bfef-4418-dcd5-f6c3bf1f7cd5"
      },
      "source": [
        "relu.mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False,  True],\n",
              "       [ True, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bKEi834uJXS",
        "outputId": "7c0b45c3-2c58-4761-8509-069cbfaad7bd"
      },
      "source": [
        "dout = np.array([[-0.1, 3.0],\n",
        "                 [1.3, -1.1]]) # 양수였던 부분들의 미분값이 음수, 음수였던 부분들의 미분값이 양수\n",
        "\n",
        "relu.backward(dout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1,  0. ],\n",
              "       [ 0. , -1.1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwv19xJpMSq"
      },
      "source": [
        "## $\\sigma$(시그모이드) 함수 구현\n",
        "* 순전파\n",
        "\n",
        "  * $\n",
        "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
        "$\n",
        "\n",
        "  * $\n",
        "y = \\sigma(x)\n",
        "$\n",
        "---\n",
        "* 역전파\n",
        "\n",
        "  * $\n",
        "y^{\\prime} = \\sigma (x)(1-\\sigma(x))\n",
        "$\n",
        "\n",
        "  * $y^{\\prime} = y(1-y)\n",
        "$\n",
        "\n",
        "* 시그모이드 레이어에서 순전파 때 기억하고 있어야 할 값 : $y$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA5MySDLyu1z"
      },
      "source": [
        "class Sigmoid:\n",
        "\n",
        "    def __init__(self):\n",
        "        # y 를 out이라고 정의\n",
        "        self.out = None\n",
        "\n",
        "    def forward(sefl, x):\n",
        "        out = 1 / (1 + np.exp(-x)) # 시그모이드 계산\n",
        "        self.out = out # 역전파 때 사용하기 위함\n",
        "    \n",
        "    def backward(self,dout):\n",
        "        dx = dout * self.out * (1 - self.out) # 미분값 * y (1-y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9noyMH2dz1xO"
      },
      "source": [
        "## Affine 계층\n",
        "* `forward`\n",
        "  * 입력값 `x`와 가중치 `W`의 내적 + `b`( `XW + b` )\n",
        "  * **평탄화**\n",
        "    * 이미지가 들어 올 수도 있고( 2차원 이상의 배열 ), 일반적인 행렬이 들어올 수도 있다.\n",
        "    * XW+b형식의 내적을 하기 위해서는 어떠한 데이터든 평탄화가 필요할 것\n",
        "      * 평탄화가 진행 됐다는 이야기는 원래 데이터의 형상을 사용하지 않겠다는 뜻이 된다. - 원본 데이터의 형상이 무시됨\n",
        "  * 원본 데이터의 모양을 **저장**\n",
        "  * N차원 배열 형태로 입력이 되었으면 N차원 배열 형태로 미분값을 전달 해야 한다.\n",
        "    * 원본 입력 배열의 형상을 유지\n",
        "* `backward`\n",
        "  1. 미분값(`dout`)과 가중치의 전치행렬(`W.T`)의 내적 ( 입력값에 대한 미분값 )\n",
        "$ \\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y} \\cdot W^{T} $\n",
        "  2. 입력값의 전치행렬(`X.T`)과 미분값(`dout`)의 내적 ( 가중치에 대한 미분값 ) $ \\frac{\\partial L}  {\\partial W} = X^{T}\\cdot\\frac{\\partial L}{\\partial Y} $\n",
        "  3. 편향은 배치를 축으로 해서 합을 구한다. (`axis = 0`)\n",
        "  4. 입력값의 형상으로 미분값(`dx`)의 형상을 바꿔준다.\n",
        "    * 예를 들어 N차원 입력을 받았으면, 미분값도 N차원 입력 배열의 형상이 되어야 한다.\n",
        "\n",
        "**저장해야 할 값**\n",
        "  1. 원본 `x`의 형상(shape) - 역전파 할 때 미분 값의 형상을 원본 입력 배열의 형상으로 재구성 할 것\n",
        "  2. 원본 `x`의 데이터 - W의 기울기를 구하기 위해 필요함(x.T을 사용하기 위함)\n",
        "  3. 가중치, 편향 (W, b)\n",
        "  4. `dW, db` : 가중치와 편향의 미분값\n",
        "    * 나중에 경사하강법 때 사용해야 하기 때문\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtu1Q3D8CPmF"
      },
      "source": [
        "class Affine:\n",
        "\n",
        "    # Affine 계충을 초기화 할 때는 이미 만들어진 가중치와 편향을 받아올 것\n",
        "    def __init__(self, W,b):\n",
        "        # 1. 가중치, 편향, 입력값 x도 정의만\n",
        "\n",
        "        # 전체적으로 사용할 변수들을 `정의`만\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "        self.x = None\n",
        "        \n",
        "        # 2. x의 형상\n",
        "        # x에 대한 역전파를 수행할 때 모양(shape)이 바뀌어 버린x의 미분값의 형상을 원래대로 돌려놓기 위해 x의 형상을 저장할 예정\n",
        "        # 순전파 떄 (N, 28, 28, 1) -> 평탄화 -> (N,784)\n",
        "        # 역전파 때 (N, 784) -> 원본 모양으로 복구 -> (N, 28, 28, 1)의 모양으로 미분값 행렬을 구할 수 있다.\n",
        "        self.original_x_shape = None\n",
        "\n",
        "        # 3. W와 b의 기울기 배열\n",
        "        #  최적화(Optimization)을 위해 각 매개변수의 미분값을 가지고 있어야 한다.\n",
        "        #  추후에 경사하강법 등을 구현하기 위해서 사용\n",
        "        #  dW, db를 사용해서 W와 b를 갱신(update)하는 것을 <<학습>>이라고 한다.\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self,x):\n",
        "        # 텐서 대응을 위해 입력값 x의 형상을 저장\n",
        "        # ex) -> (3,2,2) - 3개의 데이터가 (2,2) 모양으로 들어있는 형태 / 평탄화 -> (3,4) -> 역전파 할 때는 (3,2,2)\n",
        "        self.original_x_shape = x.shape\n",
        "\n",
        "        # 평탄화 진행\n",
        "        DATA_SIZE = x.shape[0]\n",
        "\n",
        "        x = x.reshape(DATA_SIZE, -1) # 평탄화\n",
        "\n",
        "        self.x = x # 역전파 때 가중치에 곱하기 위해서 저장(x,T)\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "\n",
        "        # 입력값 x의 미분값\n",
        "        dx = np.dot(dout, self.W.T) # 미분값 * W의 전치행렬\n",
        "\n",
        "        # 가중치 W의 미분값\n",
        "        self.dW = np.dot(self.x.T, dout) # x의 전치행렬 * 미분값\n",
        "\n",
        "        # 편향 b의 미분값 ( 배치의 방향(N 방향 - axis=0) 으로 더해준다. )\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        dx = dx.reshape(*self.original_x_shape) # (12, 3) -> *(12, 3) -> 12, 3 으로 언패킹 된다.\n",
        "        \n",
        "        return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVA7LGZbNG89"
      },
      "source": [
        "softmax, loss를 구하기 위한 각종 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "564Lg9-HG1q2"
      },
      "source": [
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "# 수치미분 함수\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 값 복원\n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOzvdU88NKjR"
      },
      "source": [
        "## SoftmaxWithLoss 계층( 출력층 )\n",
        "* `softmax`에 의한 분류 및 `CEE`를 활용한 손실함수를 동시에 구현\n",
        "* `forward`\n",
        "  * softmax 적용 및 loss 구하기\n",
        "    * 정답 레이블(`t`)\n",
        "    * 예측값 ( 소프트맥스 결과물 )\n",
        "    * loss값 ( 기록용 )\n",
        "* `backward`\n",
        "  * 순수한 오차(`y-t`)를 구해서 이전층에 전달\n",
        "  * 주의사항 : `t`가 OHE이 되어 있는지, 안되어 있는지에 따라서 코드가 달라진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aifq6USeOo1r"
      },
      "source": [
        "class SoftmaxWithLoss:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y    = None # 소프트맥스 결과물 예측값 저장( 역전파 때 사용 )\n",
        "        self.t    = None # 정답 레이블 ( 역전파 때 사용 )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1): # dout이 1인 이유 : d돈통 / d포스기\n",
        "        # 배치 고려하기 ( 미분값 평균을 구하기 위해 )\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        # t가 원-핫 인코딩이 되어있는지, 안되어있는지 고려\n",
        "        # 원소의 개수를 비교\n",
        "\n",
        "        #t가 원-핫 인코딩이 되어 있는 경우\n",
        "        # ex) t = [0, 1, 0, 0], y = [0.1, 0.7, 0.1, 0.1]\n",
        "        #     t.size = 4, y.size = 4\n",
        "\n",
        "        #t가 원-핫 인코딩이 안 되어 있는 경우\n",
        "        # ex) t = [2], y = [0.1, 0.7, 0.1, 0.1]\n",
        "        #     t.size = 1, y.size = 4\n",
        "        if self.t.size == self.y.size: # 출력층의 원소 개수를 비교하는 것은 원-핫 인코딩이 되어있는 t\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "\n",
        "            # 원-핫 인코딩이 되어있지 않는 t는 정답 레이블의 인덱스로 생각할 수 있다.\n",
        "            # y = [[0.2, 0.1, 0.7]], t = 2\n",
        "            # dx[np.arange(batch_size), self.t] -> dx[0, 2] -> 0.7 -> 0.7-1 로 오차를 구함\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW2TUUa0Q-Ru"
      },
      "source": [
        "# 신경망 레이어를 이용해서 MNIST 분류 네트워크를 구축"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F201_mzySar_"
      },
      "source": [
        "from collections import OrderedDict # 추가 순서가 유지되는 dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qksxjagnSeN_"
      },
      "source": [
        "* 일반 `dict`는 데이터 추가 순서 유지 x\n",
        "* OrderedDict는 데이터 추가 순서 유지 o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1BaF-QboalZ"
      },
      "source": [
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        # 매개변수 초기화(가중치, 편향)\n",
        "        self.params = {}\n",
        "\n",
        "        # 1층 은닉층을 위한 매개변수\n",
        "        self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "\n",
        "        # 2층 출력층을 위한 매개변수\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # 레이어 배치\n",
        "        self.layers = OrderedDict() # 레이어 추가의 순서가 유지되어야 하기 때문에 OrderedDict 생성\n",
        "\n",
        "        # Affine 1층 + 활성화 계층(Relu)\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['ReLu'] = ReLU()\n",
        "\n",
        "        # Affine 2층 + SoftmaxWithLoss(출력층)\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        # 항상 마지막 층은 SoftmaxWithLoss가 되어야 한다.\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self,x):\n",
        "        # 순전파\n",
        "        # self.layers에 들어있는 레이어들을 순서대로 꺼내서 forward 해주면 된다.\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def loss(self, x, t):\n",
        "        # predict를 하고, predict에 대한 loss를 구하면 된다.\n",
        "\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)# softmax와 loss를 동시에 구했다!\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        # 예측을 하고, 정답이랑 얼마나 틀렸는지를 계산\n",
        "        # 단, t가 원-핫 인코딩이 되어있는지, 안되어있는지가 중요!\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1) # 제일 큰 값 하나만 뽑자.( 제일 확률이 높은 곳에 위치한 인덱스를 갖는다. )\n",
        "\n",
        "        # 원-핫 인코딩 처리\n",
        "        # t.ndim != 1 --> t가 원핫 인코딩이 되어있는 상태라면\n",
        "        # t에서 제일 높은 인덱스를 찾겠다.\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "\n",
        "        return accuracy  \n",
        "\n",
        "    # 역전파를 이용해서 기울기 구하기\n",
        "    def gradient(self, x, t):\n",
        "        # 역전파를 하기 위해 필요한 것\n",
        "        # 1. 오차를 먼저 구해야 한다.\n",
        "        # 오차를 구하려면? 예측(predict)를 통해서 loss를 계산 해야 오차를 구할 수 있다.\n",
        "\n",
        "        self.loss(x,t) # 오차 발생\n",
        "\n",
        "        # 역전파\n",
        "        dout = 1 # dLoss / dLoss (d돈통 / d포스기)\n",
        "\n",
        "        # SoftmaxWithLoss의 미분값 구하기\n",
        "        \n",
        "        dout = self.lastLayer.backward(dout) # 순수한 오차가 나온다\n",
        "\n",
        "        # 순전파 때 활용한 레이어 다 가지고 와서 거꾸로 역전파 하기\n",
        "        layers = list(self.layers.values()) #  레이어를 모두 가지고 와서\n",
        "        layers.reverse() # 순서를 거꾸로 뒤집어 준다.\n",
        "\n",
        "        for layer in layers:\n",
        "\n",
        "            # 미분값을 집어 넣어가면서 역전파!\n",
        "            dout = layer.backward(dout)\n",
        "        \n",
        "        # 구해진 미분값(기울기) 가중치, 편향의 미분값\n",
        "        grads = {}\n",
        "\n",
        "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n",
        "\n",
        "    # 구식 방법. 수치미분을 활용해서 기울기 구하기( 사용하지 않습니다. 왜? 느리니까..)\n",
        "    def numerical_gradient_params(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "            \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "            \n",
        "        return grads\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBR-mOabqbWt"
      },
      "source": [
        "수치 미분과 오차역전파를 했을 때의 기울기 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCIzAAp5us5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d06816-cc13-4f43-e17e-1e0ae31bfc5c"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "mnist = datasets.mnist\n",
        "\n",
        "(X_train, t_train), (X_test, t_test) = mnist.load_data()\n",
        "\n",
        "# t_train에 대한 OHE (여기서는 필요 없다)\n",
        "t_train_dummy = OneHotEncoder().fit_transform(t_train.reshape(-1,1)).toarray()\n",
        "t_test_dummy = OneHotEncoder().fit_transform(t_test.reshape(-1,1)).toarray()\n",
        "\n",
        "# feature 전처리\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_train = X_train / 255.0\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "X_test = X_test / 255.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iB6WCUQvg1I",
        "outputId": "3b155b97-8dcf-434f-e9bf-d5edcb3a7619"
      },
      "source": [
        "network = TwoLayerNet(input_size = 28 * 28, hidden_size = 50, output_size = 10)\n",
        "\n",
        "X_batch = X_train[:3]\n",
        "t_batch = t_train[:3]\n",
        "\n",
        "# 수치 미분을 활용한 기울기 배열\n",
        "\n",
        "grads_numerical = network.numerical_gradient_params(X_batch, t_batch)\n",
        "\n",
        "# 오차 역전파를 이용한 기울기 배열\n",
        "grads_backprop = network.gradient(X_batch, t_batch)\n",
        "\n",
        "keys = ['W1', 'b1', 'W2', 'b2']\n",
        "for key in keys:\n",
        "    diff = np.average(np.abs(grads_backprop[key] - grads_numerical[key])) # 각각의 매개변수 별로 기울기의 절대값의 평균\n",
        "    print(f'key: {key} / Diff : {diff}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key: W1 / Diff : 3.8009959332780736e-10\n",
            "key: b1 / Diff : 2.1525495392783974e-09\n",
            "key: W2 / Diff : 6.2995674339205176e-09\n",
            "key: b2 / Diff : 1.3975686413286726e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea0dZHQgwfN4"
      },
      "source": [
        "오차 역전파로 기울기를 구했을 때랑, 수치미분으로 기울기를 구했을 때랑 차이가 거의 없다는 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdXd_EVvwnH_"
      },
      "source": [
        "MNIST 최종 테스트 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPe-f8gE1lDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d934443b-241c-47df-ab83-0a6da509f4a9"
      },
      "source": [
        "network = TwoLayerNet(input_size=28*28, hidden_size=50, output_size=10)\n",
        "\n",
        "# 하이퍼 파라미터 설정\n",
        "iter_num = 10000 # 학습 반복 횟수\n",
        "learning_rate = 0.1 # 학습률\n",
        "batch_size = 100 # 배치 사이즈\n",
        "train_size = X_train.shape[0] # 훈련할 이미지의 개수\n",
        "\n",
        "# 훈련 과정을 1 에폭마다 기록( 시각화 )\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "\n",
        "test_loss_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 에폭 횟수 구하기\n",
        "#  BATCH를 이용해서 전체 데이터를 모두 사용하면 1에폭\n",
        "#   100개의 배치를 이용해서 600번의 훈련을 반복하면 총 60000개(전체 데이터의 개수)의 데이터로 훈련 하는 것\n",
        "#   이 때가 1 에폭\n",
        "\n",
        "iter_per_epoch = int(max(train_size / batch_size, 1)) # max를 한 이유 : 종종 train_size < batch_size 일 때는 한번만 학습\n",
        "\n",
        "for i in range(iter_num):\n",
        "  # 미니 배치 생성\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  X_batch = X_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "\n",
        "  # 훈련 1 단계 - 기울기 계산\n",
        "  grads = network.gradient(X_batch, t_batch) # 역전파를 이용해 기울기를 계산\n",
        "\n",
        "  # 훈련 2 단계 - 경사하강법 수행(최적화 - Optimization)\n",
        "  for key in[\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "    # network의 params에는 실제 가중치, 편향 - 얘들을 갱신\n",
        "    # grads에는 dL/W1, dL/W2, dL/b1, dL/b2\n",
        "\n",
        "    network.params[key] -= learning_rate * grads[key] # 매개변수 갱신\n",
        "  \n",
        "  # 1에폭 마다 정확도, loss 확인\n",
        "  if i % iter_per_epoch == 0:  # 600번 돌 때마다 기록( 1에폭 마다 기록 )\n",
        "    train_loss = network.loss(X_batch, t_batch)\n",
        "    train_acc = network.accuracy(X_train, t_train)\n",
        "\n",
        "    test_loss = network.loss(X_test, t_test)\n",
        "    test_acc  = network.accuracy(X_test, t_test)\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    test_loss_list.append(test_loss)\n",
        "    test_acc_list.append(test_acc)\n",
        "\n",
        "    print(\"Train Accuracy : {:.6f} / Test Accuracy : {:.6f} / Train Loss : {:.6f} / Test Loss : {:.6f}\".format(train_acc, test_acc, train_loss, test_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy : 0.137583 / Test Accuracy : 0.132000 / Train Loss : 2.300763 / Test Loss : 2.301617\n",
            "Train Accuracy : 0.906017 / Test Accuracy : 0.911000 / Train Loss : 0.252737 / Test Loss : 0.316519\n",
            "Train Accuracy : 0.924283 / Test Accuracy : 0.926600 / Train Loss : 0.134813 / Test Loss : 0.256342\n",
            "Train Accuracy : 0.937500 / Test Accuracy : 0.936900 / Train Loss : 0.158151 / Test Loss : 0.216291\n",
            "Train Accuracy : 0.945917 / Test Accuracy : 0.945700 / Train Loss : 0.193566 / Test Loss : 0.191408\n",
            "Train Accuracy : 0.948867 / Test Accuracy : 0.946900 / Train Loss : 0.069993 / Test Loss : 0.179771\n",
            "Train Accuracy : 0.956683 / Test Accuracy : 0.953200 / Train Loss : 0.053541 / Test Loss : 0.160669\n",
            "Train Accuracy : 0.960967 / Test Accuracy : 0.957500 / Train Loss : 0.106062 / Test Loss : 0.146151\n",
            "Train Accuracy : 0.964367 / Test Accuracy : 0.962400 / Train Loss : 0.116488 / Test Loss : 0.135771\n",
            "Train Accuracy : 0.966917 / Test Accuracy : 0.962100 / Train Loss : 0.085356 / Test Loss : 0.131629\n",
            "Train Accuracy : 0.969850 / Test Accuracy : 0.964500 / Train Loss : 0.072371 / Test Loss : 0.125100\n",
            "Train Accuracy : 0.971467 / Test Accuracy : 0.966500 / Train Loss : 0.057960 / Test Loss : 0.118323\n",
            "Train Accuracy : 0.972600 / Test Accuracy : 0.966200 / Train Loss : 0.061199 / Test Loss : 0.116283\n",
            "Train Accuracy : 0.975783 / Test Accuracy : 0.966800 / Train Loss : 0.030970 / Test Loss : 0.112388\n",
            "Train Accuracy : 0.975417 / Test Accuracy : 0.966200 / Train Loss : 0.042076 / Test Loss : 0.108597\n",
            "Train Accuracy : 0.977933 / Test Accuracy : 0.968300 / Train Loss : 0.029661 / Test Loss : 0.104582\n",
            "Train Accuracy : 0.977583 / Test Accuracy : 0.968800 / Train Loss : 0.102156 / Test Loss : 0.105619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6-r8Mi94cJ-"
      },
      "source": [
        "import matplotlib .pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "DVlVP92P4zhB",
        "outputId": "2b0ea2be-6aa8-46ce-d41d-e78f37ec426f"
      },
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(np.arange(len(train_loss_list)), train_loss_list, label=\"train loss\")\n",
        "plt.plot(np.arange(len(test_loss_list)), test_loss_list, label=\"test loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgX8xffl43Ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "99ff1390-e9ad-46bc-8e07-d75ca57923c2"
      },
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(np.arange(len(train_acc_list)), train_acc_list, label=\"Train Accuracy\")\n",
        "plt.plot(np.arange(len(test_acc_list)), test_acc_list, label=\"Test Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK0vLaZc4VB0"
      },
      "source": [
        "# 딥러닝을 공부하기 위한 준비\n",
        "1. 수학 - 선형 대수 공부\n",
        "    * 분류, 회귀 모델을 잘 이해하기 위함\n",
        "2. 수학 - 확률, 통계\n",
        "    * 생성 모델\n",
        "3. 파이썬만을 이용한 네트워크 구축 (간단하게 참고만)\n",
        "    * 코딩 못해도 좋음!\n",
        "    * 신경망 이라는 것이 어떻게 작동하는지는 파악하는 것이 좋다."
      ]
    }
  ]
}